<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Liangwang Ruan">
  <title>MGPCG</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="/assets/reveal.js/dist/reset.css">
  <link rel="stylesheet" href="/assets/reveal.js/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="/assets/reveal.js/dist/theme/white.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">MGPCG</h1>
  <p class="author">Liangwang Ruan</p>
  <p class="date">2020-10-2</p>
</section>

<section>
<section id="g-gradient" class="title-slide slide level1">
<h1>G: Gradient</h1>

</section>
<section id="gradient-descent" class="slide level2">
<h2>Gradient Descent</h2>
<div>
<ul>
<li class="fragment"><strong>Problem</strong>: <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{b}\)</span>, <span class="math inline">\(\mathbf{A}\)</span> is SPD(symmetric positive-definite)</li>
<li class="fragment">The solution <span class="math inline">\(\mathbf{x}^*\)</span> minimize this function:<span class="math inline">\(f(\mathbf{x}) = \frac{1}{2}\mathbf{x}^TA\mathbf{x}-\mathbf{x}^T\mathbf{b}\)</span></li>
<li class="fragment"><strong>Property</strong>: The gradient at <span class="math inline">\(\mathbf{x}\)</span> is <span class="math inline">\(\nabla f = \mathbf{A}\mathbf{x}-\mathbf{b}=-\mathbf{r}\)</span></li>
<li class="fragment">Iterative solver: <span class="math inline">\(\mathbf{x}_{k+1} = \mathbf{x}_k + \alpha_k \mathbf{r}_k\)</span>, find <span class="math inline">\(\alpha_k\)</span> to minimize <span class="math inline">\(f(\mathbf{x}_{k+1})\)</span></li>
</ul>
</div>
</section>
<section id="gradient-descent-algorithm" class="slide level2">
<h2>Gradient Descent Algorithm</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="cf">while</span> r.norm() <span class="op">&gt;</span> err:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>    r <span class="op">=</span> b <span class="op">-</span> A<span class="op">*</span>x</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>    a <span class="op">=</span> r.dot(r)<span class="op">/</span>(r.transpose()<span class="op">*</span>A<span class="op">*</span>r)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>    x <span class="op">=</span> x <span class="op">+</span> a<span class="op">*</span>r</span></code></pre></div>
<div>
<ul>
<li class="fragment"><strong>drawback</strong>: Slow convergence</li>
</ul>
</div>
</section></section>
<section>
<section id="cg-conjugacy" class="title-slide slide level1">
<h1>CG: +Conjugacy</h1>

</section>
<section id="conjugacy" class="slide level2">
<h2>conjugacy</h2>
<ul>
<li><span class="math inline">\(\mathbf{A}\)</span> is SPD</li>
<li><strong>Definition</strong>: <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> are <strong>conjugate</strong> if <span class="math display">\[
\langle \mathbf{u},\mathbf{v}\rangle_A := \mathbf{u}^T\mathbf{A}\mathbf{v} =0
\]</span></li>
</ul>
</section>
<section id="conjugate-vectors-basis" class="slide level2">
<h2>Conjugate Vectors Basis</h2>
<div>
<ul>
<li class="fragment"><strong>Property</strong>: <span class="math inline">\(P=\{\mathbf{p}_0,\cdots,\mathbf{p}_{n-1}\}\)</span> and <span class="math inline">\(\langle \mathbf{p}_i, \mathbf{p}_j \rangle_A = \delta_{ij}\)</span>, then <span class="math inline">\(P\)</span> forms a basis of <span class="math inline">\(\mathbb{R}^n\)</span></li>
<li class="fragment">Suppose the solution of <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{b}\)</span> is <span class="math inline">\(\mathbf{x}^*\)</span>, we can decompose it as <span class="math display">\[
\mathbf{x}^* = \sum_{i=0}^{n-1}\alpha_i\mathbf{p}_i\]</span></li>
<li class="fragment">Using conjugacy property we have:<span class="math inline">\(\alpha_k = \frac{\langle \mathbf{p}_k, \mathbf{b}\rangle}{\langle \mathbf{p}_k, \mathbf{p}_k\rangle_A}\)</span></li>
</ul>
</div>
</section>
<section id="as-interative-solver" class="slide level2">
<h2>As Interative Solver</h2>
<div class="columns">
<div class="column" style="width:70%;">
<div>
<ul>
<li class="fragment">Find a sequence of <span class="math inline">\(n\)</span> conjugate directions and corresponding <span class="math inline">\(\alpha_k\)</span></li>
<li class="fragment">Stop for at most <span class="math inline">\(n\)</span> steps or even faster if <span class="math inline">\(P\)</span> is well choosed, faster than steepest descent</li>
<li class="fragment">No need to calculate the inverse of the Hessian matrix like in Newton method</li>
<li class="fragment">How to find <span class="math inline">\(P\)</span>?</li>
</ul>
</div>
</div><div class="column" style="width:30%;">
<p><img data-src="/assets/images/conjugate-gradient.png" height="400" /></p>
</div>
</div>
</section>
<section id="key-observation" class="slide level2">
<h2>Key Observation</h2>
<div>
<ul>
<li class="fragment">Suppose <span class="math inline">\(P\)</span> is known, and <span class="math inline">\(\mathbf{r}_0 = \mathbf{p}_0\)</span></li>
<li class="fragment">Follow iteration steps, let <span class="math inline">\(\alpha_k\)</span> minimize <span class="math inline">\(f(\mathbf{x}_k+\alpha_k\mathbf{p}_k)\)</span>, then we have <span class="math inline">\(\alpha_k = \frac{\mathbf{r}_k^T\mathbf{p}_k}{\langle \mathbf{p}_k, \mathbf{p}_k \rangle_A}\)</span></li>
<li class="fragment"><strong>Define</strong>: <span class="math inline">\(B_k = span\{\mathbf{p}_0,\cdots,\mathbf{p}_{k-1}\}\)</span></li>
<li class="fragment"><strong>Theorem</strong>: <span class="math inline">\(\mathbf{x}_k\)</span> minimize <span class="math inline">\(f(\mathbf{x})\)</span> in subspace <span class="math inline">\(\mathbf{x}_0+B_k\)</span>, since <span class="math inline">\(B_n = \mathbb{R}^n\)</span>, <span class="math inline">\(\mathbf{x}_n = \mathbf{x}^*\)</span></li>
<li class="fragment"><strong>Lemma</strong>: <span class="math inline">\(\mathbf{r}_k \perp B_k\)</span></li>
</ul>
</div>
<aside class="notes">
<ul>
<li><span class="math inline">\(\mathbf{r}_k\)</span> is gradient, so lemma leads to theorem</li>
<li>step k is the best result in <span class="math inline">\(B_k\)</span>, stronger insurance than pure gradient descentb</li>
<li>proof using SPD property and P is conjugate basis</li>
</ul>
</aside>
</section>
<section id="inductive-proof" class="slide level2">
<h2>Inductive Proof</h2>
<div>
<ul>
<li class="fragment">Initially <span class="math inline">\(\mathbf{r}_0 \perp B_0=\phi\)</span></li>
<li class="fragment"><span class="math inline">\(\mathbf{r}_{k+1} \perp \mathbf{p}_k\)</span> since <span class="math inline">\(\alpha_k\)</span> minimize <span class="math inline">\(f(\mathbf{x}_k+\alpha_k\mathbf{p}_k)\)</span> and <span class="math inline">\(\mathbf{r}_{k+1}=-\nabla f(\mathbf{x}_{k+1})\)</span></li>
<li class="fragment"><span class="math inline">\(\mathbf{r}_{k+1} = \mathbf{b} - \mathbf{A}\mathbf{x}_{k+1}=\mathbf{r}_k-\alpha_k\mathbf{A}\mathbf{p}_k\)</span></li>
<li class="fragment"><span class="math inline">\(\mathbf{r}_k \perp B_k\)</span> (induction) and <span class="math inline">\(\alpha_k\mathbf{A}\mathbf{p}_k \perp B_k\)</span> (conjugacy) <span class="math inline">\(\implies \mathbf{r}_{k+1} \perp B_k\)</span></li>
<li class="fragment"><span class="math inline">\(\implies \mathbf{r}_{k+1} \perp B_{k+1}\)</span></li>
</ul>
</div>
</section>
<section id="key-observation-1" class="slide level2">
<h2>Key Observation</h2>
<div>
<ul>
<li class="fragment">Let <span class="math inline">\(P\)</span> be <span class="math inline">\(\{\mathbf{r}_k\}\)</span>’s Gram-Schimidt orthogonalization: <span class="math inline">\(\mathbf{p}_i = \mathbf{r}_i + \sum_{k=0}^{i-1}\beta_{ik}\mathbf{p}_k\)</span></li>
<li class="fragment">Rewrite <span class="math inline">\(\mathbf{r}_i = \mathbf{p}_i - \sum_{k=0}^{i-1}\beta_{ik}\mathbf{p}_k\)</span>, also <span class="math inline">\(\mathbf{r_k} \perp B_k\)</span> <span class="math inline">\(\implies \mathbf{r}_i^T\mathbf{r}_j=0\)</span> for <span class="math inline">\(i \neq j\)</span>, <span class="math inline">\(\{\mathbf{r}_k\}\)</span> is othogonal basis</li>
<li class="fragment"><span class="math inline">\(\beta_{ik} = - \frac{\mathbf{r}_i^T\mathbf{A}\mathbf{p}_k}{\langle \mathbf{p}_k,\mathbf{p}_k\rangle_A}\)</span> also <span class="math inline">\(\mathbf{r}_{k+1}=\mathbf{r}_k-\alpha_k\mathbf{A}\mathbf{p}_k\)</span> <span class="math inline">\(\implies \beta_{ik}=\frac{\mathbf{r}_i^T\mathbf{r}_{k+1}-\mathbf{r}_i^T\mathbf{r}_{k}}{\mathbf{r}_k^T\mathbf{r}_k}\)</span> non-zero when <span class="math inline">\(k=i-1\)</span></li>
<li class="fragment">Then can be simplified to <span class="math inline">\(\mathbf{p}_k = \mathbf{r}_k-\beta_{k-1}\mathbf{P}_{k-1}\)</span>, where <span class="math inline">\(\beta_{k-1} = \frac{\mathbf{r}_k^T\mathbf{r}_k}{\mathbf{r}_{k-1}^T\mathbf{r}_{k-1}}\)</span></li>
</ul>
</div>
</section>
<section id="conjugate-gradient-algorithm" class="slide level2">
<h2>Conjugate Gradient Algorithm</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a>r <span class="op">=</span> b <span class="op">-</span> A<span class="op">*</span>x</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>p <span class="op">=</span> r</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>p_pre <span class="op">=</span> p</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>r_pre <span class="op">=</span> r</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a><span class="cf">while</span> r.norm() <span class="op">&gt;</span> err <span class="kw">and</span> k <span class="op">&lt;</span> n:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>    alpha <span class="op">=</span> r.dot(r)<span class="op">/</span>(p.transpose()<span class="op">*</span>A<span class="op">*</span>p)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a>    x <span class="op">=</span> x <span class="op">+</span> alpha<span class="op">*</span>p_pre</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>    r <span class="op">=</span> r_pre <span class="op">-</span> alpha<span class="op">*</span>A<span class="op">*</span>p_pre</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a>    beta <span class="op">=</span> r.dot(r)<span class="op">/</span>r_pre.dot(r_pre)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a>    p <span class="op">=</span> r <span class="op">+</span> beta<span class="op">*</span>p_pre</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a>    p_pre <span class="op">=</span> p</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a>    r_pre <span class="op">=</span> r</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true"></a>    k <span class="op">+=</span> <span class="dv">1</span></span></code></pre></div>
</section>
<section id="convergence" class="slide level2">
<h2>Convergence</h2>
<ul>
<li><strong>Theorem</strong>: <span class="math inline">\(\mathbf{e}_i = \mathbf{x}_i-\mathbf{x}^*\)</span>, <span class="math inline">\(\kappa(\mathbf{A})\)</span> is condition number <span class="math inline">\(\lVert \mathbf{A}^{-1} \rVert\cdot \lVert \mathbf{A} \rVert\)</span>, then <span class="math display">\[\lVert\mathbf{e}_k\rVert_\mathbf{A} \leq 2\left( \frac{\sqrt{\kappa(\mathbf{A})}-1}{\sqrt{\kappa(\mathbf{A})}+1} \right)^k \lVert \mathbf{e}_0 \rVert_\mathbf{A}\]</span></li>
<li>Smaller <span class="math inline">\(\kappa(\mathbf{A})\)</span>, Faster Convergence!</li>
</ul>
</section></section>
<section>
<section id="pcg-precondition" class="title-slide slide level1">
<h1>PCG: +Precondition</h1>

</section>
<section id="preconditioning" class="slide level2">
<h2>Preconditioning</h2>
<div>
<ul>
<li class="fragment"><span class="math inline">\(\mathbf{M}\)</span> is a SPD matrix that approximates <span class="math inline">\(\mathbf{A}\)</span> but easy to invert</li>
<li class="fragment"><span class="math inline">\(\mathbf{M}^{-1}\mathbf{A}\)</span> is better conditioned than <span class="math inline">\(\mathbf{A}\)</span></li>
<li class="fragment">Suppose <span class="math inline">\(\mathbf{M} = \mathbf{E}\mathbf{E}^T\)</span>, we can solve <span class="math display">\[\mathbf{E}^{-1}\mathbf{A}\mathbf{E}^{-T}\hat{\mathbf{x}} = \mathbf{E}^{-1}b,\ \hat{\mathbf{x}} = \mathbf{E}^T\mathbf{x}\]</span></li>
</ul>
</div>
</section>
<section id="variable-substitutions" class="slide level2">
<h2>Variable Substitutions</h2>
<div>
<ul>
<li class="fragment">Directly apply preconditioning to CG we can get something like <span class="math inline">\(\alpha_k = \frac{\hat{\mathbf{r}}_k^T\hat{\mathbf{r}}_k}{\hat{\mathbf{p}}_k^T\mathbf{E}^{-1}\mathbf{A}\mathbf{E}^{-T}\hat{\mathbf{p}}_k}\)</span></li>
<li class="fragment">To simplify, let <span class="math inline">\(\mathbf{r}_i = \mathbf{E}\hat{\mathbf{r}}_i\)</span>, <span class="math inline">\(\mathbf{p}_i = \mathbf{E}^{-T}\hat{\mathbf{p}}_i\)</span>, <span class="math inline">\(\mathbf{x} = \mathbf{E}^{-T}\hat{\mathbf{x}}\)</span>, <span class="math inline">\(\mathbf{E}^{-T}\mathbf{E}^{-1}=\mathbf{M}^{-1}\)</span></li>
<li class="fragment"><span class="math inline">\(\mathbf{E}\)</span> disappears, only <span class="math inline">\(\mathbf{M}^{-1}\)</span> left, <span class="math inline">\(\alpha_k = \frac{\mathbf{r}_k^T\mathbf{M}^{-1}\mathbf{r}_k}{\mathbf{p}_k^T\mathbf{A}\mathbf{p}_k}\)</span></li>
</ul>
</div>
</section>
<section id="pcg-algorithm" class="slide level2">
<h2>PCG Algorithm</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>r <span class="op">=</span> b <span class="op">-</span> A<span class="op">*</span>x</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>p <span class="op">=</span> M.inverse()<span class="op">*</span>r</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>p_pre <span class="op">=</span> p</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>r_pre <span class="op">=</span> r</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a><span class="cf">while</span> r.norm() <span class="op">&gt;</span> err <span class="kw">and</span> k <span class="op">&lt;</span> n:</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a>    alpha <span class="op">=</span> r.transpose()<span class="op">*</span>M.inverse()<span class="op">*</span>r<span class="op">/</span>(p.transpose()<span class="op">*</span>A<span class="op">*</span>p)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>    x <span class="op">=</span> x <span class="op">+</span> alpha<span class="op">*</span>p_pre</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a>    r <span class="op">=</span> r_pre <span class="op">-</span> alpha<span class="op">*</span>A<span class="op">*</span>p_pre</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>    beta <span class="op">=</span> r.transpose()<span class="op">*</span>M.inverse()<span class="op">*</span>r<span class="op">/</span>r_pre.transpose()<span class="op">*</span>M.inverse()<span class="op">*</span>r_pre</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a>    p <span class="op">=</span> M.inverse()<span class="op">*</span>r <span class="op">+</span> beta<span class="op">*</span>p_pre</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a>    p_pre <span class="op">=</span> p</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a>    r_pre <span class="op">=</span> r</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a>    k <span class="op">+=</span> <span class="dv">1</span></span></code></pre></div>
</section>
<section id="different-m" class="slide level2">
<h2>Different M</h2>
<div>
<ul>
<li class="fragment"><strong>Jacobi</strong>: <span class="math inline">\(\mathbf{M} = diag\{a_{11}, a_{22}, \cdots, a_{nn}\}\)</span></li>
<li class="fragment"><strong>Block Jacobi</strong>: blocked diagnal</li>
<li class="fragment"><strong>Incomplete Cholesky</strong>: imcomplete Cholesky Factorization(<span class="math inline">\(\mathbf{A}=\mathbf{R}^T\mathbf{R}\)</span> where <span class="math inline">\(\mathbf{R}\)</span> is upper triangle matrix), <span class="math inline">\(\mathbf{M}=\hat{\mathbf{R}}^T\hat{\mathbf{R}}\)</span>, not for all <span class="math inline">\(\mathbf{A}\)</span></li>
<li class="fragment">If <span class="math inline">\(\mathbf{A}\)</span> is irreducibly diagonally dominant, <strong>ICPCG</strong> works, that is
<ul>
<li class="fragment"><span class="math inline">\(\lvert a_{jj} \rvert \geq \sum_{i\neq j} \lvert a_{ij} \rvert\)</span>, <span class="math inline">\(j=1,\cdots,n\)</span></li>
<li class="fragment">no permutation such that <span class="math inline">\(\mathbf{P}\mathbf{A}\mathbf{P}^T=diag\{\mathbf{A}_1,\mathbf{A}_2\}\)</span></li>
</ul></li>
</ul>
</div>
</section></section>
<section>
<section id="mg-multigrid" class="title-slide slide level1">
<h1>MG: MultiGrid</h1>

</section>
<section id="jacobi-iteration-relaxation" class="slide level2">
<h2>Jacobi Iteration (Relaxation)</h2>
<div>
<ul>
<li class="fragment"><strong>Define</strong>: <span class="math inline">\(\mathbf{A} = \mathbf{D} + \mathbf{L} + \mathbf{U}\)</span></li>
<li class="fragment">At every step: <span class="math inline">\(\mathbf{x}_{n+1} = -\mathbf{D}^{-1}(\mathbf{L}+\mathbf{U})\mathbf{x}_n+\mathbf{D}^{-1}\mathbf{b}\)</span></li>
<li class="fragment">Iteration matrix: <span class="math inline">\(\mathbf{T} = -\mathbf{D}^{-1}(\mathbf{L}+\mathbf{U})\)</span></li>
<li class="fragment"><strong>Define</strong>(spectral radius): <span class="math inline">\(\rho(\mathbf{T})=\max \{|\lambda_1|, \cdots, |\lambda_n|\}\)</span></li>
<li class="fragment"><strong>Theorem</strong>: <span class="math inline">\(\lVert \mathbf{e}_k \rVert \leq \rho(\mathbf{T})^k\lVert \mathbf{e}_0 \rVert\)</span>, usually we have <span class="math inline">\(\rho(\mathbf{T}) = 1-O(\frac{1}{n^2})\)</span>, slow convergence when large <span class="math inline">\(n\)</span></li>
</ul>
</div>
</section>
<section id="a-simple-case" class="slide level2">
<h2>A Simple Case</h2>
<div>
<ul>
<li class="fragment"><strong>Problem</strong>: <span class="math inline">\(\frac{d^2 u}{dx^2}=0\)</span>, <span class="math inline">\(u(0)=0\)</span>, <span class="math inline">\(u(1)=0\)</span></li>
<li class="fragment">Analytical solution: <span class="math inline">\(u=0\)</span></li>
<li class="fragment">Discretize <span class="math inline">\([0,1]\)</span> into <span class="math inline">\(N\)</span> elements <span class="math inline">\(\implies \mathbf{A}\mathbf{u}=\mathbf{0}\)</span>, where <span class="math display">\[\mathbf{A}=\begin{pmatrix}
  2 &amp; -1 &amp; &amp;  \\
  -1 &amp; 2 &amp; -1 &amp;  \\
  &amp;  &amp; \ddots &amp; \\
  &amp; &amp; -1 &amp; 2
\end{pmatrix}\]</span></li>
</ul>
</div>
</section>
<section id="try-jacobi" class="slide level2">
<h2>Try Jacobi</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div>
<ul>
<li class="fragment"><span class="math inline">\(\mathbf{T}=-\mathbf{D}^{-1}(\mathbf{L}+\mathbf{U})=\mathbf{I}-\frac{1}{2}\mathbf{A}\)</span></li>
<li class="fragment"><span class="math inline">\(\mathbf{A}\mathbf{w}=\lambda\mathbf{w} \implies\)</span> <span class="math inline">\(\mathbf{w}^k=\{0, \frac{k\pi}{N},\cdots, \frac{(N-1)k\pi}{N}\}\)</span>, <span class="math inline">\(\lambda^k = 4\sin^2(\frac{k\pi}{2N})\)</span></li>
<li class="fragment"><span class="math inline">\(1-\frac{1}{2}\lambda^k=1-2\sin^2(\frac{k\pi}{2N})\)</span></li>
<li class="fragment"><strong>low</strong> frequency components converge <strong>slower</strong></li>
</ul>
</div>
</div><div class="column" style="width:40%;">
<p><img data-src="/assets/images/w-lambda.png" height="400" /></p>
</div>
</div>
</section>
<section id="key-observation-2" class="slide level2">
<h2>Key Observation</h2>
<div>
<ul>
<li class="fragment">Coarse grid can be used to compute an improved initial guess for the fine grid</li>
<li class="fragment">Relaxation on coarse grid is much faster</li>
<li class="fragment">Iteration:
<ul>
<li class="fragment">relax on <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{b}\)</span> on coarser grid (<span class="math inline">\(\Omega^{2h}\)</span>)</li>
<li class="fragment"><strong>Prolongation</strong>: interpolation solution onto finer grid (<span class="math inline">\(\Omega^h\)</span>) as initial guess</li>
<li class="fragment">relax on <span class="math inline">\(\Omega^h\)</span></li>
</ul></li>
<li class="fragment">What if the error still has smooth components when we get to the fine grid?</li>
</ul>
</div>
</section>
<section id="key-observation-3" class="slide level2">
<h2>Key Observation</h2>
<div>
<ul>
<li class="fragment">After relaxation on <span class="math inline">\(\Omega^h\)</span> the error is smooth, more oscillatory on coarser grid</li>
<li class="fragment">For any vector <span class="math inline">\(\mathbf{x}\)</span>, error <span class="math inline">\(\mathbf{e}=\mathbf{x}^*-\mathbf{x}\)</span> satisfies <span class="math inline">\(\mathbf{A}\mathbf{e}=\mathbf{r}\)</span>, where <span class="math inline">\(\mathbf{r}=\mathbf{b}-\mathbf{A}\mathbf{x}\)</span></li>
<li class="fragment">Error Correction
<ul>
<li class="fragment"><strong>Restriction</strong>: restrict the residual from <span class="math inline">\(\Omega^h\)</span> to <span class="math inline">\(\Omega^{2h}\)</span></li>
<li class="fragment">Relaxation <span class="math inline">\(\mathbf{A}\mathbf{e}=\mathbf{r}\)</span> on <span class="math inline">\(\Omega^{2h}\)</span> to get <span class="math inline">\(\mathbf{e}^{2h}\)</span></li>
<li class="fragment">Interpolation back to <span class="math inline">\(\Omega^{h}\)</span> and add it to <span class="math inline">\(\mathbf{x}^h\)</span></li>
</ul></li>
</ul>
</div>
</section>
<section id="two-grid-scheme" class="slide level2">
<h2>Two-grid scheme</h2>
<div>
<ul>
<li class="fragment">Relax <span class="math inline">\(\mathbf{A}^h\mathbf{x}^h=\mathbf{b}^h\)</span> on <span class="math inline">\(\Omega^h\)</span> to get <span class="math inline">\(\mathbf{x}^h\)</span></li>
<li class="fragment">Compute residual: <span class="math inline">\(\mathbf{r}^h = \mathbf{b}^h-\mathbf{A}^h\mathbf{x}^h\)</span></li>
<li class="fragment">Restrict the residual to <span class="math inline">\(\Omega^{2h}\)</span>: <span class="math inline">\(\mathbf{r}^{2h}=\mathbf{I}_{h}^{2h}\mathbf{r}^h\)</span></li>
<li class="fragment">Solve <span class="math inline">\(\mathbf{A}^{2h}\mathbf{e}^{2h}=\mathbf{r}^{2h}\)</span> on <span class="math inline">\(\Omega^{2h}\)</span></li>
<li class="fragment">Prolong the error to <span class="math inline">\(\Omega^h\)</span>: <span class="math inline">\(\mathbf{e}^h=\mathbf{I}_{2h}^h\mathbf{e}^{2h}\)</span></li>
<li class="fragment">Correct solution: <span class="math inline">\(\mathbf{x}^h \gets \mathbf{x}^h+\mathbf{e}^h\)</span></li>
<li class="fragment">Relax on <span class="math inline">\(\Omega^h\)</span> again using <span class="math inline">\(\mathbf{x}^h\)</span> as initial guess</li>
</ul>
</div>
</section>
<section id="v-cycle-algorithm" class="slide level2">
<h2>V-Cycle Algorithm</h2>
<p><img data-src="/assets/images/multigrid.png" height="400" /></p>
</section>
<section id="different-types" class="slide level2">
<h2>Different Types</h2>
<p><img data-src="/assets/images/MultigridWork.svg" style="width:100.0%" /></p>
</section>
<section id="mg-as-preconditioner" class="slide level2">
<h2>MG as Preconditioner</h2>
<div>
<ul>
<li class="fragment">Begin with zero initial guess at <span class="math inline">\(\Omega^h\)</span> <span class="math inline">\(\implies\)</span> procedure is linear operation</li>
<li class="fragment">To insure SPD, sufficient conditions are:
<ul>
<li class="fragment">restriction/prolongation operations are transpose of one another</li>
<li class="fragment">smoother used in upstroke and downstroke should be in reverse order</li>
<li class="fragment">the solve at coarsest level should be exact or SPD insured iteration method</li>
</ul></li>
</ul>
</div>
</section></section>
<section>
<section id="mgpcg-for-fluid" class="title-slide slide level1">
<h1>MGPCG for Fluid</h1>

</section>
<section id="background" class="slide level2">
<h2>Background</h2>
<ul>
<li><strong>Problem</strong>: <span class="math inline">\(\nabla^2p=f\)</span> in <span class="math inline">\(\Omega\)</span>, <span class="math inline">\(p(\mathbf{x})=\alpha(\mathbf{x})\)</span> on <span class="math inline">\(\Gamma_D\)</span>, <span class="math inline">\(p_n(\mathbf{x})=\beta(\mathbf{x})\)</span> on <span class="math inline">\(\Gamma_N\)</span></li>
</ul>
<div class="fragment">
<ul>
<li><strong>Discretization</strong>: <span class="math inline">\(\frac{1}{h^2}\sum_{(i&#39;,j&#39;,k&#39;)\in N^*_{ijk}}p_{i&#39;j&#39;k&#39;}-p_{ijk}=f_{ijk}\)</span>, where <span class="math inline">\(N^*_{ijk}=\{(i&#39;,j&#39;,k&#39;) \in N_{ijk}: cell (i&#39;,j&#39;,k&#39;) \notin \Gamma_N\}\)</span></li>
</ul>
<p><img data-src="/assets/images/mgpcg-discretization.png" style="width:100.0%" /></p>
</div>
</section>
<section id="prolongationrestriction" class="slide level2">
<h2>Prolongation/Restriction</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li><span class="math inline">\(R=B\otimes B\otimes B\)</span></li>
<li><span class="math inline">\(P^T=8B\otimes B\otimes B\)</span></li>
</ul>
</div><div class="column" style="width:40%;">
<p><img data-src="/assets/images/mgpcg-restriction.png" /></p>
</div>
</div>
</section>
<section id="smooth" class="slide level2">
<h2>Smooth</h2>
<ul>
<li>No explicit matrix stored</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="co"># the same as Stable Fluids!</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a><span class="at">@ti.kernel</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a><span class="kw">def</span> smooth(l: ti.template(), phase: ti.template()):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a><span class="co"># phase = red/black Gauss-Seidel phase</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>  <span class="cf">for</span> i, j, k <span class="kw">in</span> r[l]:</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>    <span class="cf">if</span> (i <span class="op">+</span> j <span class="op">+</span> k) <span class="op">&amp;</span> <span class="dv">1</span> <span class="op">==</span> phase:</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a>      z[l][i,j,k] <span class="op">=</span> (r[l][i,j,k]<span class="op">+</span>z[l][i<span class="op">+</span><span class="dv">1</span>,j,k]<span class="op">+</span>z[l][i<span class="op">-</span><span class="dv">1</span>,j,k] <span class="op">\</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a>        <span class="op">+</span>z[l][i,j<span class="op">+</span><span class="dv">1</span>,k]<span class="op">+</span>z[l][i,j<span class="op">-</span><span class="dv">1</span>,k] <span class="op">\</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a>        <span class="op">+</span>z[l][i,j,k<span class="op">+</span><span class="dv">1</span>]<span class="op">+</span>z[l][i,j,k<span class="op">-</span><span class="dv">1</span>])<span class="op">/</span><span class="fl">6.0</span></span></code></pre></div>
</section>
<section id="boundary" class="slide level2">
<h2>Boundary</h2>
<ul>
<li>Only prolongate/restrict into interior cells</li>
<li>Extra smoothing on boundary band cells</li>
</ul>
</section></section>
<section id="reference" class="title-slide slide level1">
<h1>Reference</h1>
<ul>
<li>Jonathan Richard Shewchuk, <a href="https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf">An Introduction to the Conjugate Gradient Method Without the Agonizing Pain</a></li>
<li>William L. Briggs, <a href="https://www.math.ust.hk/~mawang/teaching/math532/mgtut.pdf">A Multigrid Tutorial</a></li>
<li>A. McAdams, E. Sifakis, and J. Teran. 2010. <a href="http://pages.cs.wisc.edu/~sifakis/papers/mgpcg_poisson.pdf">A parallel multigrid Poisson solver for fluids simulation on large grids</a>. In Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA ’10). Eurographics Association, Goslar, DEU, 65–74.</li>
</ul>
</section>
    </div>
  </div>

  <script src="/assets/reveal.js/dist/reveal.js"></script>

  // reveal.js plugins
  <script src="/assets/reveal.js/plugin/notes/notes.js"></script>
  <script src="/assets/reveal.js/plugin/search/search.js"></script>
  <script src="/assets/reveal.js/plugin/zoom/zoom.js"></script>
  <script src="/assets/reveal.js/plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
